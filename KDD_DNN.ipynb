{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD99 Deep Nueral Network Intrusion Detection\n",
    "\n",
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output as clr\n",
    "from sklearn.utils import class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kk\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "import keras.regularizers as kr\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from sklearn.preprocessing import LabelEncoder as LE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory :  /media/abhikcr/New Volume/Study/M.tech 1st Sem/Cyber Security/Homeworks/KDD/extracted/\n"
     ]
    }
   ],
   "source": [
    "dir_path = (os.getcwd()+'\\\\').replace(\"\\\\\",\"/\")\n",
    "print(\"Working Directory : \", dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fucntions to Load files.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readlines(fname, start, end):\n",
    "#     fname = 'kddcup.data.corrected'\n",
    "    file = open(fname)\n",
    "    batch = []\n",
    "    r = end - start\n",
    "    for i in range(start):\n",
    "        line = file.readline()\n",
    "    for i in range(r):\n",
    "        line = file.readline()\n",
    "        batch.append(line.split(','))\n",
    "    file.close()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmreadlines(fname, size, ntypes):\n",
    "#     fname = 'kddcup.data.corrected'\n",
    "    Nobs = file_len(fname)\n",
    "    choices = np.sort(np.random.choice(Nobs,size, replace=False))\n",
    "    flag = False\n",
    "    k = 0\n",
    "    \n",
    "    file = open(fname)\n",
    "    batch = []\n",
    "    uniq = []\n",
    "    \n",
    "    for i in range(Nobs):\n",
    "\n",
    "        line = file.readline()\n",
    "        var = line.split(',')\n",
    "        size = len(var)\n",
    "        val = var[size-1]\n",
    "        \n",
    "        if(val not in uniq):\n",
    "            batch.append(var)\n",
    "            uniq.append(val)\n",
    "            if(len(uniq) == ntypes):\n",
    "                flag = True\n",
    "        \n",
    "        if(k<choices.shape[0]):\n",
    "            if(choices[k] == i):\n",
    "                batch.append(line.split(','))\n",
    "                k = k+1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            if(flag):\n",
    "                break;\n",
    "    \n",
    "    file.close()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Splitting data in train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(fname, trainname, testname):\n",
    "    Nobs = file_len(fname)\n",
    "    tfp = int(Nobs*0.25)\n",
    "    choices = np.sort(np.random.choice(Nobs,tfp, replace=False))\n",
    "    k = 0\n",
    "    file = open(fname)\n",
    "    filetr = open(trainname, 'w')\n",
    "    filets = open(testname, 'w')\n",
    "    \n",
    "    uniq_pro = []\n",
    "    uniq_srv = []\n",
    "    uniq_flg = []\n",
    "    \n",
    "    uniq = []\n",
    "    \n",
    "    for i in range(Nobs):\n",
    "        \n",
    "        line = file.readline()\n",
    "        \n",
    "        var = line.split(',')\n",
    "        arr_small  = var[1:4]\n",
    "        \n",
    "        \n",
    "        size = len(var)\n",
    "        val = var[size-1]\n",
    "        \n",
    "        if(val in uniq):\n",
    "            pass\n",
    "        else:\n",
    "            filets.write(line)\n",
    "            uniq.append(val)\n",
    "            \n",
    "        if(arr_small[0] not in uniq_pro):\n",
    "            uniq_pro.append(arr_small[0])\n",
    "            \n",
    "        if(arr_small[1] not in uniq_srv):\n",
    "            uniq_srv.append(arr_small[1])\n",
    "            \n",
    "        if(arr_small[2] not in uniq_flg):\n",
    "            uniq_flg.append(arr_small[2])\n",
    "        \n",
    "        \n",
    "        if(k<choices.shape[0]):\n",
    "            if(choices[k] == i):\n",
    "                filets.write(line)\n",
    "                k = k+1\n",
    "            else:\n",
    "                filetr.write(line)\n",
    "        else:\n",
    "            filetr.write(line)\n",
    "            \n",
    "    filets.close()\n",
    "    filetr.close()\n",
    "    file.close()\n",
    "    return Nobs, choices.shape[0], [uniq_pro,uniq_srv, uniq_flg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already spliited dont repeat...\n",
    "split = False\n",
    "if(split):\n",
    "    Nobs, test_size, cat_uniqs = split_file('kddcup.data.corrected', 'train','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tcp', 'udp', 'icmp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.save('uniqs',cat_uniqs)\n",
    "cat_uniqs = list(np.load('uniqs.npy'))\n",
    "cat_uniqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trainning data batchwise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myArrayConverter(arr):\n",
    "    '''\n",
    "    To convert string to floats\n",
    "    '''\n",
    "    convertArr = []\n",
    "    for s in arr.ravel():    \n",
    "        try:\n",
    "            value = float(s)\n",
    "        except ValueError:\n",
    "            value = s\n",
    "        convertArr.append(value)\n",
    "    return array(convertArr,dtype=object).reshape(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "trainfile = 'train_red.npy'\n",
    "testfile = 'test_red.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacth Processing...\n",
    "\n",
    "Function to convert categorical Y values to one_hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = pd.read_csv('training_attack_types', delimiter = ' ', index_col = False, names =['type', 'category'])\n",
    "label_list = label_list.assign(id_type=(label_list['type']).astype('category').cat.codes)\n",
    "label_list = label_list.assign(id_cat=(label_list['category']).astype('category').cat.codes)\n",
    "label_list = label_list.append({'type':'normal', 'category':'normal','id_type':'-1','id_cat':'-1'}, ignore_index = True)\n",
    "label_list['id_type'] = label_list['id_type'].astype(int)+1\n",
    "label_list['id_cat'] = label_list['id_cat'].astype(int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>id_type</th>\n",
       "      <th>id_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back</td>\n",
       "      <td>dos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buffer_overflow</td>\n",
       "      <td>u2r</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftp_write</td>\n",
       "      <td>r2l</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guess_passwd</td>\n",
       "      <td>r2l</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imap</td>\n",
       "      <td>r2l</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ipsweep</td>\n",
       "      <td>probe</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>land</td>\n",
       "      <td>dos</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loadmodule</td>\n",
       "      <td>u2r</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multihop</td>\n",
       "      <td>r2l</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nmap</td>\n",
       "      <td>probe</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>perl</td>\n",
       "      <td>u2r</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phf</td>\n",
       "      <td>r2l</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>portsweep</td>\n",
       "      <td>probe</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rootkit</td>\n",
       "      <td>u2r</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>satan</td>\n",
       "      <td>probe</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>smurf</td>\n",
       "      <td>dos</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spy</td>\n",
       "      <td>r2l</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>teardrop</td>\n",
       "      <td>dos</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>warezclient</td>\n",
       "      <td>r2l</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>warezmaster</td>\n",
       "      <td>r2l</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type category  id_type  id_cat\n",
       "0              back      dos        1       1\n",
       "1   buffer_overflow      u2r        2       4\n",
       "2         ftp_write      r2l        3       3\n",
       "3      guess_passwd      r2l        4       3\n",
       "4              imap      r2l        5       3\n",
       "5           ipsweep    probe        6       2\n",
       "6              land      dos        7       1\n",
       "7        loadmodule      u2r        8       4\n",
       "8          multihop      r2l        9       3\n",
       "9           neptune      dos       10       1\n",
       "10             nmap    probe       11       2\n",
       "11             perl      u2r       12       4\n",
       "12              phf      r2l       13       3\n",
       "13              pod      dos       14       1\n",
       "14        portsweep    probe       15       2\n",
       "15          rootkit      u2r       16       4\n",
       "16            satan    probe       17       2\n",
       "17            smurf      dos       18       1\n",
       "18              spy      r2l       19       3\n",
       "19         teardrop      dos       20       1\n",
       "20      warezclient      r2l       21       3\n",
       "21      warezmaster      r2l       22       3\n",
       "22           normal   normal        0       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nClasses = label_list.shape[0]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample batching....\n",
    "#currpos = 0\n",
    "# batch = readlines(trainfile, currpos, currpos + batch_size)\n",
    "batcharr = np.load(trainfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833529, 42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batcharr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batcharr[:,:-1]\n",
    "\n",
    "Y = batcharr[:,-1]\n",
    "Y_num = np.ones(Y.shape)\n",
    "Y_num[Y == 'normal.'] = 0\n",
    "Y_cat = Y_num.copy()\n",
    "Y_type = Y_num.copy()\n",
    "\n",
    "for i in label_list['type']:\n",
    "\n",
    "    Y_cat[Y == i + \".\"] = label_list[label_list['type'] == i]['id_cat']\n",
    "    Y_type[Y == i+ \".\"] = label_list[label_list['type'] == i]['id_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.',\n",
       "       'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.',\n",
       "       'neptune.', 'nmap.', 'normal.', 'perl.', 'phf.', 'pod.',\n",
       "       'portsweep.', 'rootkit.', 'satan.', 'smurf.', 'spy.', 'teardrop.',\n",
       "       'warezclient.', 'warezmaster.'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see class imbalance bacth wise....\n",
    "labels = np.unique(Y)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch class imbalance reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuiq,cnt = np.unique(Y_type, return_counts = True)\n",
    "maxval = max(cnt)\n",
    "\n",
    "X_new = X.copy()\n",
    "Y_new = Y.copy()\n",
    "\n",
    "for i in range(nuiq.shape[0]):\n",
    "    \n",
    "    Ytypedd = Y[Y_type == nuiq[i]]\n",
    "    \n",
    "    Xdd = X[Y_type == nuiq[i]]\n",
    "    \n",
    "    times = int(500/Ytypedd.shape[0])\n",
    "\n",
    "#     print(times)\n",
    "#     print(np.tile(Xdd, (times,1)).shape, X.shape)\n",
    "    \n",
    "    X_new = np.concatenate([X_new , np.tile(Xdd, (times,1))], axis = 0)\n",
    "    Y_new = np.concatenate([Y_new , np.tile(Ytypedd, times)], axis = 0)\n",
    "    \n",
    "    Ytypedd = None\n",
    "    Xdd =None\n",
    "    gc.collect()\n",
    "    \n",
    "X = X_new\n",
    "Y = Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839810, 41)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_num = class_weight.compute_class_weight('balanced',np.unique(Y_num),Y_num)\n",
    "cw_cat = class_weight.compute_class_weight('balanced',np.unique(Y_cat),Y_cat)\n",
    "cw_type = class_weight.compute_class_weight('balanced',np.unique(Y_type),Y_type)\n",
    "cws_num = np.arange(2)*0.0\n",
    "cws_num[np.unique(Y_num).astype(int)] = cw_num\n",
    "cws_cat = np.arange(5)*0.0\n",
    "cws_cat[np.unique(Y_cat).astype(int)] = cw_cat\n",
    "cws_type = np.arange(23)*0.0\n",
    "cws_type[np.unique(Y_type).astype(int)] = cw_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_num = np.ones(Y.shape)\n",
    "Y_num[Y == 'normal.'] = 0\n",
    "Y_cat = Y_num.copy()\n",
    "Y_type = Y_num.copy()\n",
    "\n",
    "for i in label_list['type']:\n",
    "    Y_cat[Y == i+str('.')] = label_list[label_list['type'] == i]['id_cat']\n",
    "    Y_type[Y == i+str('.')] = label_list[label_list['type'] == i]['id_type']\n",
    "\n",
    "Y_num_hot = one_hot(Y_num.astype(int), 2)\n",
    "Y_cat_hot = one_hot(Y_cat.astype(int), 5)\n",
    "Y_type_hot = one_hot(Y_type.astype(int), 23)\n",
    "\n",
    "X_new_hot = np.delete(X,[1,2,3],1)\n",
    "\n",
    "X_new_hot2 = X[:,[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro_le = LE()\n",
    "model_pro_ohe = OHE(handle_unknown='ignore')\n",
    "model_srv_le = LE()\n",
    "model_srv_ohe = OHE(handle_unknown='ignore')\n",
    "model_flg_le = LE()\n",
    "model_flg_ohe = OHE(handle_unknown='ignore')\n",
    "\n",
    "model_pro_ohe.fit_transform(model_pro_le.fit_transform(cat_uniqs[0]).reshape(-1,1))\n",
    "model_srv_ohe.fit_transform(model_srv_le.fit_transform(cat_uniqs[1]).reshape(-1,1))\n",
    "model_flg_ohe.fit_transform(model_flg_le.fit_transform(cat_uniqs[2]).reshape(-1,1))\n",
    "\n",
    "X_pro = model_pro_ohe.transform(model_pro_le.transform(X_new_hot2[:,0]).reshape(-1,1)).todense()\n",
    "X_srv = model_srv_ohe.transform(model_srv_le.transform(X_new_hot2[:,1]).reshape(-1,1)).todense()\n",
    "X_flg = model_flg_ohe.transform(model_flg_le.transform(X_new_hot2[:,2]).reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839810, 122)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.concatenate((X_new_hot , X_pro , X_srv, X_flg), axis = 1).astype(float)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.',\n",
       "        'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.',\n",
       "        'neptune.', 'nmap.', 'normal.', 'perl.', 'phf.', 'pod.',\n",
       "        'portsweep.', 'rootkit.', 'satan.', 'smurf.', 'spy.', 'teardrop.',\n",
       "        'warezclient.', 'warezmaster.'], dtype=object),\n",
       " array([   750,    504,    504,    532,    504,   2996,    507,    504,\n",
       "           505, 201040,   1158, 616654,    501,    504,    501,   2779,\n",
       "           505,   4081,   2397,    501,    712,    667,    504]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D = X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839810,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    \n",
    "    \n",
    "    xin = kl.Input(shape = input_shape)\n",
    "    x = kl.Dense(1024, activation='relu',kernel_regularizer=kr.l2(0.01))(xin)\n",
    "#     x = kl.Dropout(rate = 0.3)(x)\n",
    "    x = kl.Dense(128, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "#     x = kl.Dense(60, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "#     x = kl.Dense(64, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "#     x = kl.Dense(20, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "#     x = kl.Dense(16, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "    \n",
    "#     x = kl.Dense(10, activation='tanh',kernel_regularizer=kr.l2(0.1))(x)\n",
    "#     x = kl.Dropout(rate = 0.4)(x)\n",
    "    x1 = kl.Dense(16, activation='tanh',kernel_regularizer=kr.l2(0.01))(x)\n",
    "#     x1 = kl.Dropout(rate = 0.8)(x1)\n",
    "    x1 = kl.Dense(8, activation='relu',kernel_regularizer=kr.l2(0.01))(x1)\n",
    "    x1out = kl.Dense(2, activation='softmax', name = 'y1out',kernel_regularizer=kr.l2(0.01))(x1)\n",
    "    \n",
    "#     x2cat = kl.Concatenate(axis=-1)([x1out, x])\n",
    "    \n",
    "    x2 = kl.Dense(32, activation='tanh',kernel_regularizer=kr.l2(0.01))(x)\n",
    "#     x2 = kl.Dropout(rate = 0.8)(x2)\n",
    "    x2 = kl.Dense(16, activation='relu',kernel_regularizer=kr.l2(0.01))(x2)\n",
    "    \n",
    "    x2out = kl.Dense(5, activation='softmax', name = 'y2out',kernel_regularizer=kr.l2(0.01))(x2)\n",
    "    \n",
    "#     x3cat = kl.Concatenate(axis=-1)([x2out, x])\n",
    "    \n",
    "    x3 = kl.Dense(64, activation='tanh',kernel_regularizer=kr.l2(0.01))(x)\n",
    "#     x3 = kl.Dropout(rate = 0.8)(x3)\n",
    "    x3 = kl.Dense(32, activation='relu',kernel_regularizer=kr.l2(0.01))(x3)\n",
    "    \n",
    "    x3out = kl.Dense(23, activation='softmax', name = 'y3out',kernel_regularizer=kr.l2(0.01))(x3)\n",
    "    \n",
    "    model = km.Model(\n",
    "        inputs=xin,\n",
    "        outputs=[x1out,x2out,x3out],\n",
    "        name=\"fashionnet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model([D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           (None, 122)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_371 (Dense)               (None, 1024)         125952      input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_372 (Dense)               (None, 128)          131200      dense_371[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_373 (Dense)               (None, 16)           2064        dense_372[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_375 (Dense)               (None, 32)           4128        dense_372[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_377 (Dense)               (None, 64)           8256        dense_372[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_374 (Dense)               (None, 8)            136         dense_373[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_376 (Dense)               (None, 16)           528         dense_375[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_378 (Dense)               (None, 32)           2080        dense_377[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "y1out (Dense)                   (None, 2)            18          dense_374[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "y2out (Dense)                   (None, 5)            85          dense_376[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "y3out (Dense)                   (None, 23)           759         dense_378[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 275,206\n",
      "Trainable params: 275,206\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# losses = {   \n",
    "#     \"y1out\": \"categorical_crossentropy\",\n",
    "#     \"y2out\": \"categorical_crossentropy\",\n",
    "#     \"y3out\": \"categorical_crossentropy\",\n",
    "# }\n",
    "losses = {\n",
    "    \"y1out\": \"categorical_hinge\",\n",
    "    \"y2out\": \"categorical_hinge\",\n",
    "    \"y3out\": \"categorical_hinge\",\n",
    "}\n",
    "\n",
    "lossWeights = {\"y1out\": 23.0, \"y2out\": 5.0, \"y3out\": 2.0}\n",
    "\n",
    "opt = ko.Nadam()\n",
    "# opt = ko.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'y1out/Softmax:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'y2out/Softmax:0' shape=(?, 5) dtype=float32>,\n",
       " <tf.Tensor 'y3out/Softmax:0' shape=(?, 23) dtype=float32>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "\n",
    "> Dont need to train if you loaded pretrained model...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/3\n",
      "318323/318323 [==============================] - 17s 54us/step - loss: 0.9141 - y1out_loss: 0.0126 - y2out_loss: 0.0356 - y3out_loss: 0.0407 - y1out_acc: 0.9939 - y2out_acc: 0.9817 - y3out_acc: 0.9792\n",
      "Epoch 2/3\n",
      "318323/318323 [==============================] - 17s 54us/step - loss: 0.9625 - y1out_loss: 0.0142 - y2out_loss: 0.0359 - y3out_loss: 0.0412 - y1out_acc: 0.9931 - y2out_acc: 0.9818 - y3out_acc: 0.9792\n",
      "Epoch 3/3\n",
      "318323/318323 [==============================] - 18s 55us/step - loss: 0.9053 - y1out_loss: 0.0127 - y2out_loss: 0.0349 - y3out_loss: 0.0411 - y1out_acc: 0.9939 - y2out_acc: 0.9825 - y3out_acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# sample training...single epoch\n",
    "train = True\n",
    "if(train):\n",
    "    for i in range(1):\n",
    "        clr()\n",
    "        print(i)\n",
    "        his = model.fit(X_new,{\"y1out\": Y_num_hot, \"y2out\": Y_cat_hot, \"y3out\": Y_type_hot},epochs=3, batch_size = 5000, validation_split = 0.0\n",
    "                  ,class_weight={\"y1out\": cws_num, \"y2out\": cws_cat, \"y3out\": cws_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving trained model last time....\n",
    "model.save('model.h5')\n",
    "# model.save('model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking on test data split....  25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318323, 42)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfile = 'test_red.npy'\n",
    "# Sample batching....\n",
    "batcharr = np.load(testfile)\n",
    "batcharr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batcharr[:,:-1]\n",
    "\n",
    "Y = batcharr[:,-1]\n",
    "Y_num = np.ones(Y.shape)\n",
    "Y_num[Y == 'normal.'] = 0\n",
    "Y_cat = Y_num.copy()\n",
    "Y_type = Y_num.copy()\n",
    "\n",
    "for i in label_list['type']:\n",
    "\n",
    "    Y_cat[Y == i + \".\"] = label_list[label_list['type'] == i]['id_cat']\n",
    "    Y_type[Y == i+ \".\"] = label_list[label_list['type'] == i]['id_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318323, 122)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_num = np.ones(Y.shape)\n",
    "Y_num[Y == 'normal.'] = 0\n",
    "Y_cat = Y_num.copy()\n",
    "Y_type = Y_num.copy()\n",
    "\n",
    "for i in label_list['type']:\n",
    "    Y_cat[Y == i+str('.')] = label_list[label_list['type'] == i]['id_cat']\n",
    "    Y_type[Y == i+str('.')] = label_list[label_list['type'] == i]['id_type']\n",
    "\n",
    "Y_num_hot = one_hot(Y_num.astype(int), 2)\n",
    "Y_cat_hot = one_hot(Y_cat.astype(int), 5)\n",
    "Y_type_hot = one_hot(Y_type.astype(int), 23)\n",
    "\n",
    "X_new_hot = np.delete(X,[1,2,3],1)\n",
    "\n",
    "X_new_hot2 = X[:,[1,2,3]]\n",
    "\n",
    "# X_new.shape\n",
    "\n",
    "model_pro_le = LE()\n",
    "model_pro_ohe = OHE(handle_unknown='ignore')\n",
    "model_srv_le = LE()\n",
    "model_srv_ohe = OHE(handle_unknown='ignore')\n",
    "model_flg_le = LE()\n",
    "model_flg_ohe = OHE(handle_unknown='ignore')\n",
    "\n",
    "model_pro_ohe.fit_transform(model_pro_le.fit_transform(cat_uniqs[0]).reshape(-1,1))\n",
    "model_srv_ohe.fit_transform(model_srv_le.fit_transform(cat_uniqs[1]).reshape(-1,1))\n",
    "model_flg_ohe.fit_transform(model_flg_le.fit_transform(cat_uniqs[2]).reshape(-1,1))\n",
    "\n",
    "X_pro = model_pro_ohe.transform(model_pro_le.transform(X_new_hot2[:,0]).reshape(-1,1)).todense()\n",
    "X_srv = model_srv_ohe.transform(model_srv_le.transform(X_new_hot2[:,1]).reshape(-1,1)).todense()\n",
    "X_flg = model_flg_ohe.transform(model_flg_le.transform(X_new_hot2[:,2]).reshape(-1,1)).todense()\n",
    "\n",
    "X_srv.shape\n",
    "\n",
    "X_new = np.concatenate((X_new_hot , X_pro , X_srv, X_flg), axis = 1).astype(float)\n",
    "\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.', 'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.', 'neptune.', 'nmap.', 'normal.', 'perl.', 'phf.', 'pod.', 'portsweep.',\n",
       "        'rootkit.', 'satan.', 'smurf.', 'spy.', 'teardrop.', 'warezclient.', 'warezmaster.'], dtype=object),\n",
       " array([   305,      7,      1,     16,      4,   1331,      8,      4,      2,  98058,    412, 213737,      1,      1,     57,    975,      5,   1703,   1195,      1,    231,    260,      9]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables, _ = np.unique(Y, return_counts = True)\n",
    "lables, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318323/318323 [==============================] - 8s 26us/step\n"
     ]
    }
   ],
   "source": [
    "lossacc = model.evaluate(X_new,{\"y1out\": Y_num_hot, \"y2out\": Y_cat_hot, \"y3out\": Y_type_hot}, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Losses, net_loss : 0.8377100313033332 , y1 : 0.010496585979162759 , y2 : 0.03530940625020098 , y3 : 0.04080048163304848\n",
      "Final Test Accuracies, y1 : 0.9951244506072934 , y2 : 0.9818423424289341 , y3 : 0.9792255042932262\n"
     ]
    }
   ],
   "source": [
    "print('Final Test Losses, net_loss :',lossacc[0],', y1 :', lossacc[1], ', y2 :', lossacc[2], ', y3 :', lossacc[3])\n",
    "print('Final Test Accuracies, y1 :', lossacc[4], ', y2 :', lossacc[5], ', y3 :', lossacc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cmat\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = model.predict(X_new, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = cmat(np.argmax(Y_num_hot, axis = 1), np.argmax(Y_preds[0], axis = 1))\n",
    "mat2 = cmat(np.argmax(Y_cat_hot, axis = 1), np.argmax(Y_preds[1], axis = 1))\n",
    "mat3 = cmat(np.argmax(Y_type_hot, axis = 1), np.argmax(Y_preds[2], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213490    247]\n",
      " [  1305 103281]]\n"
     ]
    }
   ],
   "source": [
    "print(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213654     83      0      0      0]\n",
      " [   965  98889      0      0      0]\n",
      " [  1861   2560      0      0      0]\n",
      " [   292      2      0      0      0]\n",
      " [    17      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "print(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213727      0      0      0      0      0      0      0      0      0     10      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [   305      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     7      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [    16      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     2      0      0      0      0      0      0      0      0      0      2      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [  1229      0      0      0      0      0      0      0      0      0    102      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     8      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     4      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     2      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [    75      0      0      0      0      0      0      0      0      0  97983      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [   348      0      0      0      0      0      0      0      0      0     64      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [    57      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [   625      0      0      0      0      0      0      0      0      0    350      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     5      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [    43      0      0      0      0      0      0      0      0      0   1660      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [  1187      0      0      0      0      0      0      0      0      0      8      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [    35      0      0      0      0      0      0      0      0      0    196      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [   260      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]\n",
      " [     9      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "print(mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhikcr/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prfsarr = np.array(prfs(Y, labels[np.argmax(Y_preds[2], axis = 1)], labels = labels))\n",
    "df = pd.DataFrame(prfsarr.T, columns = ['precison', 'recall', 'f_score', 'support'], index = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precison        0.000089\n",
       "recall          0.050232\n",
       "f_score         0.000177\n",
       "support     13840.130435\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.914133483202602, 0.96245527657901, 0.905327709105584],\n",
       " 'y1out_loss': [0.012634130023786836,\n",
       "  0.014200420275543349,\n",
       "  0.012699805783171663],\n",
       " 'y2out_loss': [0.03556606910464466,\n",
       "  0.03590912790976767,\n",
       "  0.034896042881448416],\n",
       " 'y3out_loss': [0.040732239565508185,\n",
       "  0.04117930016213266,\n",
       "  0.04106077331969526],\n",
       " 'y1out_acc': [0.9939055552114794, 0.9930919213206872, 0.9938898501220528],\n",
       " 'y2out_acc': [0.9816884065911847, 0.9818077830236391, 0.9824580718005345],\n",
       " 'y3out_acc': [0.9791720989529977, 0.9791626719604016, 0.9791563886530822]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thankyou for viewing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
